{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''    imports    '''\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import csv\n",
    "import re\n",
    "\n",
    "from time import time\n",
    "from pandas import read_csv\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''    functions    '''\n",
    "def printEach(list):\n",
    "    for item in list:\n",
    "        print(item)\n",
    "        \n",
    "def printBestParameter(grid_search):\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "def translateNumbers(x):\n",
    "    # translate indian numbers to arabic numbers\n",
    "    x = x.replace(u'\\u0660','0')\n",
    "    x = x.replace(u'\\u0661','1')\n",
    "    x = x.replace(u'\\u0662','2')\n",
    "    x = x.replace(u'\\u0663','3')\n",
    "    x = x.replace(u'\\u0664','4')\n",
    "    x = x.replace(u'\\u0665','5')\n",
    "    x = x.replace(u'\\u0666','6')\n",
    "    x = x.replace(u'\\u0667','7')\n",
    "    x = x.replace(u'\\u0668','8')\n",
    "    x = x.replace(u'\\u0669','9')\n",
    "    return x\n",
    "    \n",
    "def removePunc(x):    \n",
    "    # removes punctuation and arabic harakat\n",
    "    punc = \"\"\"!$%^&*()-=+.,:'\"<>/\\?\"\"\"\n",
    "    arabic_semicolon = u\"\\u061B\"\n",
    "    arabic_comma = u\"\\u060C\"\n",
    "    arabic_question = u\"\\u061F\"\n",
    "    arabia_fatha = u\"\\u064E\"\n",
    "    arabia_2fathas = u\"\\u064B\"\n",
    "    arabia_damma = u\"\\u064F\"\n",
    "    arabia_2dammas = u\"\\u064C\"\n",
    "    arabia_kasra = u\"\\u0650\"\n",
    "    arabia_2kasras = u\"\\u064D\"\n",
    "    arabic_sukun = u\"\\u0652\"\n",
    "    arabic_shadda = u\"\\u0651\"\n",
    "    punc += arabic_semicolon + arabic_comma + arabic_question + arabia_fatha + arabia_2fathas + arabia_damma + arabia_2dammas + arabia_kasra + arabia_2kasras + arabic_sukun + arabic_shadda\n",
    "    \n",
    "    for char in punc:\n",
    "        x = x.replace(char, \"\")\n",
    "        \n",
    "    return x\n",
    "\n",
    "def uniformArabic(x):\n",
    "    # uniform multiple characters to thier origrinal form\n",
    "    # Alifs -> Alif\n",
    "    x = x.replace(u'\\u0622',u'\\u0627')\n",
    "    x = x.replace(u'\\u0623',u'\\u0627')\n",
    "    x = x.replace(u'\\u0625',u'\\u0627')\n",
    "    # Taa marbotah -> haa\n",
    "    x = x.replace(u\"\\u0629\",u\"\\u0647\")\n",
    "    # Alif_maqsurah + Yaa_Hamzah -> Yaa\n",
    "    x = x.replace(u'\\u0649',u'\\u064A')\n",
    "    x = x.replace(u'\\u0626',u'\\u064A')\n",
    "    # Waw_hamzah -> waw\n",
    "    x = x.replace(u'\\u0624',u'\\u0648')\n",
    "    return x\n",
    "\n",
    "def reduceString(x, string):\n",
    "    # replaces two same consecutive characters with one\n",
    "    stringString = string+string\n",
    "    while stringString in x:\n",
    "        x = x.replace(stringString, string)\n",
    "    return x\n",
    "    \n",
    "def clean(x):\n",
    "    # cleans the tweet\n",
    "    x = translateNumbers(x)\n",
    "    \n",
    "    x = re.sub(\"(https|http)://t.co/([a-zA-Z0-9]){10}\",\" _LINK_ \",x) # Link\n",
    "    x = re.sub(\"[0-9]{10,}\",\" _NUMBER_ \",x) # Number\n",
    "    x = re.sub(\"@.*\\s\",\" _ACCOUNT_ \",x) # Account\n",
    "    \n",
    "    x = removePunc(x)\n",
    "    \n",
    "    x = uniformArabic(x)\n",
    "    \n",
    "    x = reduceString(x, ' ')\n",
    "    \n",
    "    # reduce arabic letters\n",
    "    arabic_letters = [u\"\\u0627\",u\"\\u0628\",u\"\\u062A\",u\"\\u062B\",u\"\\u062C\",u\"\\u062D\",u\"\\u062E\",u\"\\u062F\",u\"\\u0630\",u\"\\u0631\",u\"\\u0632\",u\"\\u0633\",u\"\\u0634\",u\"\\u0635\",u\"\\u0636\",u\"\\u0637\",u\"\\u0638\",u\"\\u0639\",u\"\\u063A\",u\"\\u0641\",u\"\\u0642\",u\"\\u0643\",u\"\\u0644\",u\"\\u0645\",u\"\\u0646\",u\"\\u0647\",u\"\\u0648\",u\"\\u064A\"]\n",
    "    for letter in arabic_letters:\n",
    "        x = reduceString(x, letter)\n",
    "    \n",
    "    # remove maddah\n",
    "    x = x.replace(u'\\u0640','')\n",
    "    \n",
    "    # ال + لا\n",
    "    x = reduceString(x, u'\\u0627\\u0644')\n",
    "    x = reduceString(x, u'\\u0644\\u0627')\n",
    "        \n",
    "    # english repeated letters\n",
    "    x = reduceString(x, \"a\")\n",
    "    x = reduceString(x, \"s\")\n",
    "    x = reduceString(x, \"h\")\n",
    "    x = reduceString(x, \"o\")\n",
    "    x = reduceString(x, \"y\")\n",
    "    \n",
    "    x = reduceString(x, \"_\")\n",
    "    \n",
    "    return x\n",
    "    \n",
    "def cleanAll(X):\n",
    "    # perform clean on all elements\n",
    "    clean_x = []\n",
    "    for x in X:\n",
    "        clean_x.append(clean(x))\n",
    "    return clean_x\n",
    "\n",
    "def lenFeatures(X):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vect = vectorizer.fit_transform(X)\n",
    "    print(\"There are \" + len(vectorizer.vocabulary_) + \" features\")\n",
    "        \n",
    "def listFeatures(X):\n",
    "    # list the features of the tfidf vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vect = vectorizer.fit_transform(X)\n",
    "    vocab = []\n",
    "    for voc in vectorizer.vocabulary_:\n",
    "        vocab.append(voc)\n",
    "    vocab.sort()\n",
    "    print(len(vocab))\n",
    "    print(\"\\n\")\n",
    "    for voc in vocab:\n",
    "        print voc+\"\\n\"\n",
    "\n",
    "def doGridSearch(pipeline, parameters):\n",
    "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "    t0 = time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "\n",
    "    printBestParameter(grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate 'str' and 'int' objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-230-216b53e692a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcleanAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# listFeatures(X)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mlenFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-229-e62c3ca0ff9b>\u001b[0m in \u001b[0;36mlenFeatures\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mvect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"There are \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" features\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlistFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot concatenate 'str' and 'int' objects"
     ]
    }
   ],
   "source": [
    "'''    main    '''\n",
    "df = read_csv('corpusCinema.csv', engine='python', encoding=\"UTF-8\")\n",
    "array =  df.values\n",
    "\n",
    "X = array[:, 0] #Tweet\n",
    "Y = array[:, 1] #Sentiment\n",
    "\n",
    "for n,i in enumerate(Y):\n",
    "    if i==1:\n",
    "        Y[n]=\"Positive\"\n",
    "    elif i==0:\n",
    "        Y[n]=\"Neutral\"\n",
    "    elif i==-1:\n",
    "        Y[n]=\"Negative\"\n",
    "\n",
    "X = cleanAll(X)\n",
    "# listFeatures(X)\n",
    "lenFeatures(X)\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   46.5s\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 80.018s\n",
      "Best score: 0.756\n",
      "Best parameters set:\n",
      "\t1__max_df: 0.5\n",
      "\t2__norm: 'l2'\n",
      "\t2__use_idf: False\n",
      "\t3__degree: 1\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('1', TfidfVectorizer()),\n",
    "    ('2', TfidfTransformer()),\n",
    "    ('3', SVC(kernel='linear', random_state=7, decision_function_shape='ovo'))\n",
    "])\n",
    "parameters = {\n",
    "    '1__max_df': (0.5, 1.0, 1.5),\n",
    "    \n",
    "    '2__use_idf': (True, False),\n",
    "    '2__norm': ('l1', 'l2'),\n",
    "    \n",
    "#     '3__C': (0.1, 1.0, 10),\n",
    "#     '3__tol': (1e-4,  1e-6, 1e-8),\n",
    "    #'3__class_weight': (None, 'balanced'),\n",
    "    '3__degree': ( 1,3),\n",
    "    \n",
    "}\n",
    "\n",
    "doGridSearch(pipeline, parameters)\n",
    "# done in 80.018s\n",
    "# Best score: 0.756\n",
    "# Best parameters set:\n",
    "# \t1__max_df: 0.5\n",
    "# \t2__norm: 'l2'\n",
    "# \t2__use_idf: False\n",
    "# \t3__degree: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 144 out of 144 | elapsed:   14.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 14.386s\n",
      "Best score: 0.722\n",
      "Best parameters set:\n",
      "\t1__max_df: 0.5\n",
      "\t2__norm: 'l1'\n",
      "\t2__use_idf: False\n",
      "\t3__alpha: 1e-10\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('1', TfidfVectorizer()),\n",
    "    ('2', TfidfTransformer()),\n",
    "    ('3', MultinomialNB())\n",
    "])\n",
    "parameters = {\n",
    "    '1__max_df': (0.25, 0.5, 0.75, 1.0),\n",
    "    \n",
    "    '2__use_idf': (True, False),\n",
    "    '2__norm': ('l1', 'l2'),\n",
    "    \n",
    "    '3__alpha': (1.0e-10, 1, 10),\n",
    "}\n",
    "\n",
    "doGridSearch(pipeline, parameters)\n",
    "# done in 14.386s\n",
    "# Best score: 0.722\n",
    "# Best parameters set:\n",
    "# \t1__max_df: 0.5\n",
    "# \t2__norm: 'l1'\n",
    "# \t2__use_idf: False\n",
    "# \t3__alpha: 1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 28 candidates, totalling 84 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   16.8s\n",
      "[Parallel(n_jobs=-1)]: Done  84 out of  84 | elapsed:   34.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 37.841s\n",
      "Best score: 0.722\n",
      "Best parameters set:\n",
      "\t3__class_weight: None\n",
      "\t3__criterion: 'entropy'\n",
      "\t3__n_estimators: 50\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('1', TfidfVectorizer()),\n",
    "    ('2', TfidfTransformer()),\n",
    "    ('3', RandomForestClassifier(random_state=7))\n",
    "])\n",
    "parameters = {\n",
    "#     '1__max_df': (0.25, 0.5, 0.75, 1.0), # 1.0\n",
    "#     '1__use_idf': (True, False), # true\n",
    "#     '1__norm': ('l1', 'l2'), # l2\n",
    "    \n",
    "#     '2__use_idf': (True, False), # true\n",
    "#     '2__norm': ('l1', 'l2'), # l2\n",
    "    \n",
    "    '3__n_estimators': (5, 10, 15, 20, 25, 35, 50), # 10\n",
    "    '3__criterion': ('gini', 'entropy'), # gini\n",
    "    '3__class_weight': (None, 'balanced'), # None\n",
    "}\n",
    "\n",
    "doGridSearch(pipeline, parameters)\n",
    "# done in 37.841s\n",
    "# Best score: 0.722\n",
    "# Best parameters set:\n",
    "# \t3__class_weight: None\n",
    "# \t3__criterion: 'entropy'\n",
    "# \t3__n_estimators: 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:    4.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 4.565s\n",
      "Best score: 0.724\n",
      "Best parameters set:\n",
      "\t1__max_df: 1.0\n",
      "\t2__norm: 'l2'\n",
      "\t2__use_idf: False\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('1', TfidfVectorizer()),\n",
    "    ('2', TfidfTransformer()),\n",
    "    ('3', LogisticRegression())\n",
    "])\n",
    "parameters = {\n",
    "    '1__max_df': (0.5, 0.75, 1.0),\n",
    "    \n",
    "    '2__use_idf': (True, False),\n",
    "    '2__norm': ('l1', 'l2'),\n",
    "}\n",
    "\n",
    "doGridSearch(pipeline, parameters)\n",
    "# done in 4.347s\n",
    "# Best score: 0.724\n",
    "# Best parameters set:\n",
    "# \t1__max_df: 1.0\n",
    "# \t2__norm: 'l2'\n",
    "# \t2__use_idf: False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
